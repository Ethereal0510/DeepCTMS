# A novel dual-attention deep neural network with multi-scale fusion feature processing for predicting transcription factor binding sites

The overall architectures of BERT-TFBS is presented in the following figure

![DeepCTMS](https://github.com/Ethereal0510/DeepCTMS/blob/main/image/DeepCTMS.png)

# 1.Introduce

Transcription functions as a pivotal biological process in cell biology, for which is required to complete the binding of transcription factors (TFs) to transcription factor binding sites (TFBSs) on the DNAs. Accurate prediction of TFBSs can provide great potential to regulate the expression of interested genes, which can facilitate exploration of new drugs and treatment for diseases. Although many deep learning-based models have been proposed for predicting TFBSs, existing models still have problems including neglect of DNA shape features and insufficient fusion feature processing, leading to undesirable prediction performance. In this paper, we propose a novel model called DeepCTMS, in which both sequence features and shape features of DNA slices are effectively fused to derive high-quality representations for the task of TFBSs prediction. A sequence feature processing module is firstly used to extract sparse higher-order sequence features of DNA. For the shape data of DNA slice, the three-dimensional features of DNA shape data are extracted by employing a convolutional triple attention module. Finally, a multi-scale fusion feature processing module is used to fuse sequence features and shape features to obtain representations with significantly aligned semantics of both features. The experimental results on 165 ChIP-seq datasets demonstrate that DeepCTMS consistently outperforms benchmark models on prediction performance and generalization ability. Ablation experiments demonstrate that integrating DNA shape data, convolutional triple attention module, and multi-scale fusion feature processing module can receive better prediction performance on 165 ChIP-seq datasets. Additionally, t-SNE visual analysis and cross-cell line validation also further highlight DeepCTMS 's effectiveness and generalization ability.

# 2.Dependencies

python==3.10.0

pytorch==2.4.1

numpy==1.24.1

pandas==1.4.4

scikit-learn==1.5.2

tqdm==4.65.0

# 3.Dataset

165 ChIP-seq datasets from the Encyclopedia of DNA Elements (ENCODE) project were used to evaluate the performance of the models. These datasets were obtained from 690 ChIP-seq datasets provided by the ENCODE project and cover 29 TFs from 32 cell lines. Zeng et al divided each of 165 ENCODE ChIP-seq datasets into a training set and a test set. Negative example sequences are generated by randomization, maintaining the nucleotide frequencies of the positive example sequences. The number of positive and negative examples is balanced to avoid the problem of sampling bias. DNA sequences are a fixed length of 101 base pairs (bps) with a binary tag to indicate the presence or absence of TFBS in the sequence. DNA shape data is generated by inputting DNA sequence data into the DNAshapeR tool. Here we provide a CTCF transcription factor dataset for the K562 cell line.

# 4.Start

```bash
git clone https://github.com/Ethereal0510/DeepCTMS.git
cd DeepCTMS/DeepCTMS
python train.py
```

